---
title: "Spatial Machine Learning"
author: "Justin Williams"
date: "2022-09-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages}
library(dotenv)
library(tidyverse)
library(sf)
library(tidycensus)
library(patchwork)
library(spdep)
library(car)
library(units)
library(corrr)
library(spatialreg)
library(SpatialML)
library(spgwr)
library(GWmodel)
library(leaflet)
library(mapview)
library(tmap)
library(tigris)
options(tigris_use_cache = TRUE)
```

## Load data

Load in select census data for NYC  with **tidycensus** package.

```{r set-variables}
nyc_counties <- c("Bronx","Kings","New York","Queens","Richmond")
```

### Median home variables for linear regression data

Search for variables

```{r load-variables}
v20 <- load_variables(2020, "acs5/profile", cache = TRUE)
# View(v20)
```

ACS estimates acquired are:

  - `median_valueE`: The median home value of the Census tract (our outcome variable);

  - `median_roomsE`: The median number of rooms for homes in the Census tract;

  - `total_populationE`: The total population;

  - `median_ageE`: The median age of the population in the Census tract;

  - `median_year_builtE`: The median year built of housing structures in the tract;

  - `median_incomeE`: The median income of households in the Census tract;

  - `pct_collegeE`: The percentage of the population age 25 and up with a four-year college degree;

  - `pct_foreign_bornE`: The percentage of the population born outside the United States;

  - `pct_whiteE`: The percentage of the population that identifies as non-Hispanic white alone;
  
  - `pct_blackE`: The percentage of the population that identifies as non-Hispanic black alone;
  
  - `pct_hispanicE`: The percentage of the population that identifies as Hispanic, any race;
  
  - `pct_asianE`: The percentage of the population that identifies as Asian non-hispanic Asian alone.

  - `percent_oohE`: The percentage of housing units in the tract that are owner-occupied.

```{r load-median-home-data}
# variable list
variables <- c(
  median_value = "B25077_001",
  median_rooms = "B25018_001",
  median_income = "DP03_0062",
  total_population = "B01003_001",
  median_age = "B01002_001",
  pct_college = "DP02_0068P",
  pct_foreign_born = "DP02_0094P",
  pct_white = "DP05_0077P",
  pct_black = "DP05_0078P",
  pct_hispanic = "DP05_0070P",
  pct_asian = "DP05_0080P",
  median_year_built = "B25037_001",
  percent_ooh = "DP04_0046P"
)

# get acs data
(nyc_census_data <- get_acs(
  geography = "tract",
  variables = variables,
  state = "NY",
  county = nyc_counties,
  geometry = TRUE,
  output = "wide",
  year = 2020,
  key = Sys.getenv("CENSUS_API")) %>% 
  st_transform(2263))
```

View dependent variable distribution

```{r target-variable}
(ggplot_med_income <- 
  ggplot(nyc_census_data, aes(fill = median_valueE)) +
  geom_sf(color = NA) + 
  scale_fill_viridis_c(labels = scales::label_dollar()) + 
  theme_void() + 
  labs(title = "NYC Median Home Value",
       subtitle = "(2016-2020 ACS Estimate)",
       fill = "Median home value ") +
  theme(plot.title.position = 'plot',
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)))

# # save plot
# ggsave("./images/ggplot_med_inc.png",
#        plot = ggplot_med_income,
#        bg = "white")
```

Try this with mapview

```{r mapview-version}
(mapview_nyc_med_home <- nyc_census_data %>% 
  mapview(
    zcol = "median_valueE",
    legend = T,
    layer.name = "NYC Median Home Value",
    alpha = 0.9,
    lwd=0.125,
    color = "white",
    na.alpha = 0.0))

# # save as png
# mapshot(mapview_nyc_med_home,
#         file = "./images/mapview_nyc_med_home.png")
```

Missing target values

```{r missing-target-value}
count(nyc_census_data[nyc_census_data$median_valueE == "NA",])$n
```

Histogram of `median_valueE` distribution.

```{r histogram}
(nyc_hist <- 
  nyc_census_data %>% 
  ggplot(aes(x = median_valueE)) + 
  geom_histogram(alpha = 0.5, fill = "navy", color = "navy",
                 bins = 100) + 
  theme_minimal() + 
  scale_x_continuous(labels = scales::label_dollar()) + 
  labs(x = "Median home value"))
```

Right skewed with a clustering of Census Tracts in the lower distribution and a long left tail in the expensive areas. This could lead to a violation of the normality principle let's apply some type of transformation. 

Let's try this using the `tmap` package.

```{r tmap-package}
# create plot
(nyc_median_value_hist_tm <- nyc_census_data[!st_is_empty(nyc_census_data),,drop=F] %>% 
tm_shape() +
  tm_polygons(col = "median_valueE",
          palette = "cividis",
          title = "2016-2020 ACS",
          legend.hist = TRUE,
          legend.format = scales::dollar_format()) +
  tm_layout(main.title = "NYC Median Home Value by Census Tract",
            frame = FALSE,
            legend.outside = TRUE,
            bg.color = "grey100",
            legend.hist.width = 5,
            fontfamily = "Verdana"))

# # save plot
# tmap_save(nyc_median_value_hist_tm,
#           filename = "./images/tmap_nyc_med_value_hist.png",
#           height = 7, width = 10)
```


### Transformation

Square root transformation albeit weaker then logarithmic or cubed transformations, is used for for reducing right skewness. 

```{r transform-sqrt}
ggplot_med_home_sqrt <- nyc_census_data %>% 
  ggplot(aes(fill = sqrt(median_valueE))) + 
    geom_sf(color = NA) + 
    scale_fill_viridis_c() + 
    theme_void() + 
    labs(title = "NYC Median Home Income",
       subtitle = "(2016-2020 ACS Estimate)",
       fill = "Median home\nvalue (sqrt) ") +
    theme(plot.title.position = 'plot',
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

nyc_hist_sqrt <- nyc_census_data %>% 
  ggplot(aes(x = sqrt(median_valueE))) + 
  geom_histogram(alpha = 0.5, fill = "navy", color = "navy",
                 bins = 100) + 
  theme_minimal() + 
  scale_x_continuous() + 
  labs(x = "Median home value (sqrt)")

ggplot_med_home_sqrt + nyc_hist_sqrt
```

Now in using the `tmap` package

```{r tmap-sqrt}
# create plot
(nyc_median_value_sqrt_hist_tm <- nyc_census_data[!st_is_empty(nyc_census_data),,drop=F] %>%
   mutate(sqrt_med_value = sqrt(median_valueE)) %>% 
tm_shape() +
  tm_polygons(col = "sqrt_med_value",
          palette = "cividis",
          title = "2016-2020 ACS (sqrt)",
          legend.hist = TRUE) +
  tm_layout(main.title = "NYC Median Home Value by Census Tract",
            frame = FALSE,
            legend.outside = TRUE,
            bg.color = "grey100",
            legend.hist.width = 5,
            fontfamily = "Verdana"))

# save plot
tmap_save(nyc_median_value_sqrt_hist_tm,
          filename = "./images/tmap_nyc_med_value_sqrt_hist.png",
          height = 7, width = 10)
```


### Add features, select only estimates and omit margins and NA

Added in a few features:

 - `pop_density` which measures population density in a given geogrphic area
 - `median_structure_age` which subtracts 2020 from `median_year_builtE`

```{r selectE-omit-NA}
(nyc_census_data_prepped <- nyc_census_data %>% 
  mutate(pop_density = as.numeric(set_units(total_populationE / st_area(.), "1/km2")),
         median_structure_age = 2020 - median_year_builtE) %>% 
  select(!ends_with("M")) %>% 
  rename_with(.fn = ~str_remove(.x, "E$")) %>%
  na.omit())
```

## Modeling

Let's compute a basic liner regression model using the sqrt of median_value as the dependent variable.

```{r first-model}
# write formula
formula <- "sqrt(median_value) ~ median_rooms + median_income + pct_college + pct_foreign_born + pct_white + pct_black + pct_hispanic + pct_asian + median_age + percent_ooh + median_structure_age + pop_density"

# compute model
model1 <- lm(formula = formula, data = nyc_census_data_prepped)

# view model statistics
summary(model1)
```

Highest significant p-values are `pct_foreign_born`, `median_age` and `pop_density`. The first two are both negatively correlated with `median_value`, therefore as census tracts percentage of foreign born and median age increase, median home value decreases. Much more so for `pct_foreign_born`. It looks like the denser the population, `median_value` increases. Other positively correlated values are `median_rooms`, `pct_asian`, `median_structure_age` and `pct_white`. Some of the other negatively correlated values are `percent_ooh` and `median_age`. 


## Correlation

Let's look at the correlated values

```{r correlation}
# prep for correlation
nyc_estimates <- nyc_census_data_prepped %>%
  select(-GEOID, -median_value, -median_year_built, -total_population) %>%
  st_drop_geometry()

# get correlations
correlations <- correlate(nyc_estimates, method = "pearson")

# plot correlcations
network_plot(correlations,
             min_cor = .4)
```

Variance Inflation Factor (VIF) calcs. Value of >5 suggest a level of correlation that can be problematic

```{r vif}
vif(model1)
```

## Residuals

Normality assumption of residuals.

```{r residuals}
# get model residuals
nyc_census_data_prepped$residuals <- residuals(model1)

# plot residuals hist
nyc_census_data_prepped %>% 
ggplot(aes(x = residuals)) + 
  geom_histogram(bins = 100, alpha = 0.5, color = "navy",
                 fill = "navy") + 
  theme_minimal()
```

Assumption of residual independence commonly violated in models using spatial data due to *spatial autocorrelation* in the error term. Which means model performance depends on geographic location. This can be assessed using Moran's I.

```{r moran-test}
wts <- nyc_census_data_prepped %>%
  poly2nb(snap=1e+4) %>%
  nb2listw(zero.policy=TRUE)

moran.test(nyc_census_data_prepped$residuals, wts)
```
Graph Moran's I

```{r}
nyc_census_data_prepped$lagged_residuals <- lag.listw(wts, nyc_census_data_prepped$residuals)

nyc_census_data_prepped %>% 
ggplot(aes(x = residuals, y = lagged_residuals)) + 
  theme_minimal() + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "red")
```

Shows positive spatial autocorrelation in residuals suggesting assumption of independence in error term is violated.

## Spatial regression methods

### Spatial lag

```{r spatial-lag-model}
# lag model
lag_model <- lagsarlm(
  formula = formula, 
  data = nyc_census_data_prepped, 
  listw = wts
)

# model summary
summary(lag_model, Nagelkerke = TRUE)

spatialreg::
```

R-squared is higher, and estimates are higher which illustrates the importance of controlling for spatial lag.

### Spatial regression

```{r spatial-reg}
# create model
error_model <- errorsarlm(
  formula = formula, 
  data = nyc_census_data_prepped, 
  listw = wts
)

# model summary
summary(error_model, Nagelkerke = TRUE)
```
Recompute Moran's I

```{r lag-moran}
moran.test(lag_model$residuals, wts)
```

```{r regression-moran}
moran.test(error_model$residuals, wts)
```

## From Github issue

```{r}
nb <- poly2nb(nyc_census_data_prepped)
nb
nb2listw(neighbours = nb,  zero.policy = TRUE)
# Error in print.listw(x) : 
#  regions with no neighbours found, use zero.policy=TRUE
print(nb2listw(neighbours = nb,  zero.policy = TRUE),  zero.policy = TRUE)
get.ZeroPolicyOption()
# [1] FALSE
set.ZeroPolicyOption(TRUE)
# [1] FALSE
get.ZeroPolicyOption()
# [1] TRUE
nb2listw(nb)
```
```{r}
plot(st_geometry(nyc_census_data_prepped))
plot(st_geometry(nyc_census_data)[card(nb) == 0L], add=TRUE, col="red")
```

```{r}
args(poly2nb)
# function (pl, row.names = NULL, snap = sqrt(.Machine$double.eps), 
#   queen = TRUE, useC = TRUE, foundInBox = NULL) 
sqrt(.Machine$double.eps)
#  [1] 1.490116e-08
nb <- poly2nb(nyc_census_data_prepped, snap=1e+4)
nb
```

# Geographically Weighted Random Forest (GRF) from SpatialML package

Functions to use from `SpatialML` package.
Also have to extract list of coordinates from dataset and pass those into the modeling functions.

```{r spatial-ml-functions}
# basic geographical random forest model
?SpatialML::grf()
# predict function for grf
?SpatialML::predict.grf()
```


### Extract centroid coordinates from geometry

The `grf` function from the `SpatialML` packages require a list of coordinates. We need to extract them from the `geometry` column which contains polygons for each census tract in NYC. 

We also need to create a coordinates object as `SpatialML` accepts this as a separate argument.

```{r extract-centroids}
# get centroids from each geom
nyc_census_data_prepped <- nyc_census_data_prepped %>% 
  mutate(lon = map_dbl(geometry, ~st_centroid(.x)[[1]]),
         lat = map_dbl(geometry, ~st_centroid(.x)[[2]]))

# create coords column
coords <- nyc_census_data_prepped %>% 
  st_drop_geometry() %>% 
  select(lat,lon)
```

Prep dataset for modeling

```{r prep-grf}
# drop residuals
nyc_census_grf_prepped <- nyc_census_data_prepped %>% 
  st_drop_geometry() %>% 
  select(!c(GEOID, NAM, residuals, lagged_residuals, lat, lon))
```

Model

```{r first-model}
# define formula for grf
formula_grf <- "median_value ~ median_rooms + median_income + pct_college + pct_foreign_born + pct_white + pct_black + pct_hispanic + pct_asian + median_age + percent_ooh + median_structure_age + pop_density"

# model
grf_model <- grf(formula = formula_grf,
    dframe = nyc_census_grf_prepped,
    bw=162,
    ntree = 500,
    mtry = 2,
    kernel = "adaptive",
    forests = TRUE,
    coords = coords)
```

```{r }
Income
```


Try with built-in dataset

```{r income-dataset}
data(Income)
Coords <- Income[,1:2]
grf_income <- grf(Income01 ~ UnemrT01 + PrSect01, dframe=Income, bw=60,
                kernel="adaptive", coords=Coords)
```

Need to figure out how to automate this process dependent on the dataset.
```{r wts-for-spatialreg-models}
# constructs neighbors weights for polygon
?spdep::poly2nb
# supplements a neigbors list with spatial weights for the chosen scheme
?spdep::nb2listw
```

# Geographically Weighted Regression (GWR) from GWmodels Package

Functions for modeling with the GWmodels package
```{r functions-gwmodel}
# choose bandwidth for gwr
?GWmodel::bw.gwr
# basic geographically weight regression model
?GWmodel::gwr.basic
# predict gwr
?GWmodel::gwr.predict
```

## Choosing bandwidth for GWR

Have to convert `sf` object to a `SpatialPolygonsDataFrame` as **GWmodel** does not support `sf` objects as of yet.

```{r bandwidth-gwr}
# convert to sp object
nyc_census_data_prepped_sp <- nyc_census_data_prepped %>%
  sf::as_Spatial()

# choose bandwidth
bw <- bw.gwr(
  formula = formula, 
  data = nyc_census_data_prepped_sp, 
  kernel = "bisquare",
  adaptive = TRUE
  )
```

`bw.gwr()` chose 234 as the number of nearest neighbors based on cross-validation. This means that for each Census tract, the nearest 234 of the total 2165 Census tracts in the NYC region will be used to estimate the local model, with weights calculated using the bisquare distance-decay function.

### Fit model

```{r fit-model}
gw_model <- gwr.basic(
  formula = formula, 
  data = nyc_census_data_prepped_sp, 
  bw = bw,
  kernel = "bisquare",
  adaptive = TRUE
)
```
Get model objects

```{r model-object}
names(gw_model)
```

SDF is the `SpatialPolygonsDataFrame` and we can convert it to an `sf` object.

```{r convert-results}
gw_model_results <- gw_model$SDF %>%
  st_as_sf() 

names(gw_model_results)
```

Plot results

```{r results-plot}
ggplot(gw_model_results, aes(fill = Local_R2)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c() + 
  theme_void()
```

The yellow (higher R2) sections are where the model performs better. Staten Island, parts of south-eastern Queens and Brooklyn.

# Geographically Weighted Regression (GWR) using spgwr packages

Functions for use with `spgwr` package

```{r spgwr-functions}
# finds bandwidth
?spgwr::ggwr.sel()
# basic gwr model
?spgwr::gwr()
# predict?
# looks like predictions is an arg within the basic gwr model, not exactly sure how to utilize this, will have to look up info.
```

## Get bandwidth

Have to pass this coordinates as a matrix not df.

```{r bandwidth-spgwr-gwr}
bwG <- spgwr::gwr.sel(formula = formula, 
               data = nyc_census_data_prepped, 
               gweight = gwr.Gauss, 
               coords = as.matrix(coords),
               verbose = FALSE)
bwG
```

## Fit GWR model

```{r fit-gwr-model}
gwrG <- spgwr::gwr(formula = formula, 
            data = nyc_census_data_prepped, 
            bandwidth = bwG,
            coords = as.matrix(coords),
            gweight = gwr.Gauss, 
            hatmatrix = TRUE)
gwrG
```
```{r}
data(meuse)
coordinates(meuse) <- c("x", "y")
meuse$ffreq <- factor(meuse$ffreq)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
meuse.grid$ffreq <- factor(meuse.grid$ffreq)
gridded(meuse.grid) <- TRUE
xx <- gwr(cadmium ~ dist, meuse, bandwidth = 228, hatmatrix=TRUE)
xx
x <- gwr(cadmium ~ dist, meuse, bandwidth = 228, fit.points = meuse.grid,
predict=TRUE, se.fit=TRUE, fittedGWRobject=xx)
x
spplot(x$SDF, "pred")
spplot(x$SDF, "pred.se")
```

```{r}
data(oldcol, package="spdep")
lw <- spdep::nb2listw(COL.nb)
COL.lag.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw)
COL.mix.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw,
type="mixed")
print(p1 <- predict(COL.mix.eig))
print(p2 <- predict(COL.mix.eig, newdata=COL.OLD, listw=lw, pred.type = "TS",
legacy.mixed = TRUE))

?predict()
?data(oldcol)

lw
```




